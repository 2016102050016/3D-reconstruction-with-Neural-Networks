{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.dataset as dataset\n",
    "import lib.network as network\n",
    "import lib.utils as utils\n",
    "import lib.vis as vis\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "from tensorflow.python.tools import inspect_checkpoint\n",
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=utils.read_params()\n",
    "out_dir=params[\"DIRS\"][\"OUTPUT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip=ImageSequenceClip(dataset.construct_file_path_list_from_dir(\"/Users/micmelesse/Documents/3D-reconstruction-with-neural-networks/output/02691156_131db4a650873babad3ab188d086d4db\",\".png\"),fps=2)\n",
    "clip.write_videofile(\"{}/movie.mp4\".format(out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_dir=\"models_remote/model_2018-04-02_20:10:12_L:0.1_E:40_B:16/epoch_0\"\n",
    "model_dir=os.path.dirname(epoch_dir)\n",
    "X_test,y_test=dataset.load_testset(epoch_dir)\n",
    "model_info = utils.get_model_info(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=dataset.load_random_sample()\n",
    "vis.sample(x,y,y,\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ax.get_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.write_png(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.get_pylab_image(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=dataset.load_obj_id(\"02691156_131db4a650873babad3ab188d086d4db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.sample(x,y,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"02691156_131db4a650873babad3ab188d086d4db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis.voxel_binary(yp[0],\"frame_{}\".format(i))\n",
    "image_list=utils.filter_files(\"frame*.png\")\n",
    "print(image_list)\n",
    "clip=ImageSequenceClip(image_list,fps=6)\n",
    "clip.write_videofile(\"movie.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_paths = dataset.construct_file_path_list_from_dir(\"aws\", \"loss.npy\")\n",
    "for path in loss_paths:\n",
    "    print(path)\n",
    "    print(utils.grep_learning_rate(path))\n",
    "    loss_arr = np.load(path)\n",
    "    print(loss_arr.shape)\n",
    "    plt.plot(loss_arr.flat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.load(\"voxel_prediction.npy\")\n",
    "p=np.transpose(p,[0,1,3,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp=np.load(\"voxel_prediction.npy\")[23]\n",
    "vp=np.transpose(vp,[0,2,3,1])\n",
    "vis.voxel_b(vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.voxel_binary(yp[0])\n",
    "plt.figure()\n",
    "plt.imshow(vis.voxel_ndarray(yp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=np.load(\"/Users/micmelesse/Documents/3D-reconstruction-with-neural-networks/data/ResidualGRUNet.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=utils.list_folders(\"aws\")[-1]\n",
    "png_ls=dataset.construct_file_path_list_from_dir(\"aws/model_2018-04-02_20:10:12_L:0.1_E:40_B:16\", \"_p.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in png_ls:\n",
    "    obj_id=utils.grep_obj_id(f)\n",
    "    n=utils.grep_stepcount(f)\n",
    "    new_name=os.path.dirname(f)+\"/\"+n+'_'+obj_id+'_yp.png'\n",
    "#     print(f,new_name)\n",
    "    os.rename(f,new_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(png_ls[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.grep_obj_id(\"uiudasniuansfuas_asnfasnfkasfunkasufn_x.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "LEARNING_RATE, EPOCHS=0.01,100                              # hyper paramters\n",
    "\n",
    "# Build Tensorflow Graph\n",
    "X = tf.constant([[1],[2],[3]],dtype=tf.float32)             # input\n",
    "W = tf.Variable(tf.random_uniform([3,3]),dtype=tf.float32)  # paramters\n",
    "Y = tf.matmul(W,X)                                          # prediction\n",
    "T = tf.constant([[3],[2],[1]],dtype=tf.float32)             # target label\n",
    "E = tf.reduce_mean(tf.abs(T-Y))                             # Error \n",
    "GD=tf.train.GradientDescentOptimizer(LEARNING_RATE)         # optimizing algorihtm\n",
    "Gradients = GD.compute_gradients(E)                         # compute the gradients from the Error\n",
    "TRAIN_STEP = GD.apply_gradients(Gradients)                  # use the gradients to update their paramters\n",
    "\n",
    "\n",
    "# Run Graph\n",
    "with tf.Session() as sess:                                  # start tensorflow session\n",
    "    tf.global_variables_initializer().run()                 # initialize variables\n",
    "    for i in range(EPOCHS):                                 # open pass over the dataset\n",
    "        result=sess.run([E,Y,TRAIN_STEP])                   # fetch values from tensorflow graph\n",
    "        \n",
    "print(result[0]) \n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform:0\", shape=(3, 3, 10, 10), dtype=float32)\n",
      "Tensor(\"concat:0\", shape=(3, 3, 100), dtype=float32)\n",
      "Tensor(\"transpose:0\", shape=(100, 3, 3), dtype=float32)\n",
      "Tensor(\"ExpandDims:0\", shape=(100, 3, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "kernel=tf.random_uniform([3,3,10,10])\n",
    "print(kernel)\n",
    "\n",
    "kern_1 = tf.concat(tf.unstack(kernel, axis=-1), axis=-1)\n",
    "kern_2 = tf.transpose(kern_1, [2,0,1])\n",
    "kern_3 = tf.expand_dims(kern_2, -1)\n",
    "\n",
    "print(kern_1)\n",
    "print(kern_2)\n",
    "print(kern_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_1:0\", shape=(36, 5, 127, 127, 3), dtype=float32)\n",
      "Tensor(\"concat_1:0\", shape=(36, 5, 381, 127), dtype=float32)\n",
      "Tensor(\"concat_2:0\", shape=(36, 381, 635), dtype=float32)\n",
      "Tensor(\"ExpandDims_1:0\", shape=(36, 381, 635, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ret=tf.random_uniform([36,5,127,127,3])\n",
    "print(ret)\n",
    "\n",
    "feature_map_1 = tf.concat(tf.unstack(ret, axis=4), axis=2)\n",
    "feature_map_2 = tf.concat(tf.unstack(feature_map_1, axis=1), axis=2)\n",
    "feature_map_3 = tf.expand_dims(feature_map_2, -1)\n",
    "\n",
    "print(feature_map_1)\n",
    "print(feature_map_2)\n",
    "print(feature_map_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_4:0\", shape=(3, 3, 3, 10, 10), dtype=float32)\n",
      "Tensor(\"concat_3:0\", shape=(3, 3, 3, 100), dtype=float32)\n",
      "Tensor(\"transpose_1:0\", shape=(100, 3, 3, 3), dtype=float32)\n",
      "Tensor(\"ExpandDims_2:0\", shape=(100, 3, 3, 3, 1), dtype=float32)\n",
      "Tensor(\"concat_4:0\", shape=(100, 3, 9, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "kernel=tf.random_uniform([3,3,3,10,10])\n",
    "print(kernel)\n",
    "\n",
    "kern_1 = tf.concat(tf.unstack(kernel, axis=-1), axis=-1)\n",
    "kern_2 = tf.transpose(kern_1,[3,0,1,2])\n",
    "kern_3 = tf.expand_dims(kern_2,-1)\n",
    "kern_4 = tf.concat(tf.unstack(kern_3, axis=1), axis=1)\n",
    "\n",
    "print(kern_1)\n",
    "print(kern_2)\n",
    "print(kern_3)\n",
    "print(kern_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_9:0\", shape=(2, 32, 32, 32, 2), dtype=float32)\n",
      "Tensor(\"unstack_14:0\", shape=(2, 32, 32, 32), dtype=float32)\n",
      "Tensor(\"concat_8:0\", shape=(2, 32, 1024), dtype=float32)\n",
      "Tensor(\"ExpandDims_4:0\", shape=(2, 32, 1024, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ret=tf.random_uniform([2,32,32,32,2])\n",
    "print(ret)\n",
    "\n",
    "vox_slice_1 = tf.unstack(ret, axis=4)[0]\n",
    "vox_slice_2 = tf.concat(tf.unstack(vox_slice_1, axis=3), axis=1)\n",
    "vox_slice_3 = tf.expand_dims(vox_slice_2,-1)\n",
    "\n",
    "print(vox_slice_1)\n",
    "print(vox_slice_2)\n",
    "print(vox_slice_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
