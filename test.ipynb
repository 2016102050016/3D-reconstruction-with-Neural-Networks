{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.dataset as dataset\n",
    "import lib.network as network\n",
    "import lib.path as path\n",
    "import lib.utils as utils\n",
    "from collections import deque\n",
    "from tensorflow.python.tools import inspect_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all, label_all = dataset.get_preprocessed_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        data_all, label_all, test_size=0.2)\n",
    " \n",
    "X_train, X_val, y_train, y_val =sklearn.model_selection.train_test_split(\n",
    "    X_train, y_train, test_size=0.2)\n",
    "\n",
    "X_train_batchs, y_train_batchs = dataset.get_batchs(\n",
    "    X_train, y_train, net.batch_size)\n",
    "\n",
    "X_val_batchs, y_val_batchs = dataset.get_batchs(\n",
    "    X_val, y_val, net.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([1, 2, 3, 4])\n",
      "1 5\n",
      "2 4\n",
      "3 3\n",
      "4 2\n"
     ]
    }
   ],
   "source": [
    "d=deque([1,2,3,4])\n",
    "e=deque([1,2,3,4,5])\n",
    "print(d)\n",
    "while d and e:\n",
    "    print(d.popleft(),e.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn_rate 0.1, epoch_count 2, batch_size 2\n",
      "encoder\n",
      "recurrent_module\n",
      "decoder\n",
      "loss\n",
      "optimizer\n",
      "misc op\n",
      "initalize variables\n"
     ]
    }
   ],
   "source": [
    "net=network.Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path=\"/Users/micmelesse/Documents/3D-reconstruction-with-neural-networks/out/model_2018-03-03_16:38:55_L:0.1_E:1_B:1/epoch_0\"\n",
    "net.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "x=utils.to_npy(data_all[i])\n",
    "y=utils.to_npy(label_all[i])\n",
    "y_hat=net.predict(x)\n",
    "utils.vis_multichannel(x[0][1])\n",
    "utils.vis_voxel(y[0])\n",
    "utils.vis_voxel(y_hat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
