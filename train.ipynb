{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import utils\n",
    "import random\n",
    "import layers\n",
    "import dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from network import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with a learning rate of 0.1 for 3 epochs with batchs of size 10\n"
     ]
    }
   ],
   "source": [
    "#read params\n",
    "regex=\"^.*=(.*)$\"\n",
    "with open(\"train.params\") as f:\n",
    "    learning_rate=re.findall(regex,f.readline())[0]\n",
    "    batch_size=re.findall(regex,f.readline())[0]\n",
    "    epoch=re.findall(regex,f.readline())[0]\n",
    "   \n",
    "    print(\"training with a learning rate of {} for {} epochs with batchs of size {}\".format(learning_rate,epoch,batch_size))\n",
    "model_dir=\"model_{}_{}_{}\".format(learning_rate,batch_size,epoch)\n",
    "os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 24, 137, 137, 4)\n",
      "(100, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "net=network(learning_rate)\n",
    "data_all=np.load(\"all_data.npy\")  \n",
    "label_all=np.load(\"all_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training\n",
    "\n",
    "\n",
    "# train network\n",
    "print(\"starting training at {}\".format(cur_time))\n",
    "loss_session=[]\n",
    "acc_session=[]\n",
    "for e in range(epoch):\n",
    "    perm=np.random.permutation(N)\n",
    "    data_all=data_all[perm]\n",
    "    label_all=label_all[perm]\n",
    "    split_size=math.ceil(N/batch_size)\n",
    "    data_batchs=np.array_split(data_all,split_size)\n",
    "    label_batchs=np.array_split(label_all,split_size)\n",
    "    loss_epoch=[]\n",
    "    acc_epoch=[]\n",
    "    # print(\"starting epoch_{:03d}\".format(e))\n",
    "    epoch_dir=\"{}/epoch_{:03d}\".format(train_dir,e)\n",
    "    os.makedirs(epoch_dir)\n",
    "    \n",
    "    batch_number=0\n",
    "    for data,label in zip(data_batchs,label_batchs):\n",
    "        batch_info=sess.run([net.mean_loss,net.mean_accuracy,net.optimizing_op],feed_dict={net.X:data, net.Y: label})\n",
    "        loss_batch=batch_info[0]\n",
    "        acc_batch=batch_info[1]\n",
    "        loss_epoch.append(loss_batch)\n",
    "        acc_epoch.append(acc_batch)\n",
    "        batch_number+=1\n",
    "        if batch_number%10==0:\n",
    "            print(\"epoch_{:03d}-batch_{:03d}: loss={}, acc={}\".format(e,batch_number,loss_batch,acc_batch))\n",
    "    loss_session.append(loss_epoch)\n",
    "    acc_session.append(acc_epoch)\n",
    "    net.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
