{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.dataset as dataset\n",
    "import lib.params as params\n",
    "import lib.network as network\n",
    "import lib.path as path\n",
    "import lib.utils as utils\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with a learning rate of 0.1 for 1 epochs with batchs of size 3\n",
      "initiating network...\n",
      " ...network initiated\n"
     ]
    }
   ],
   "source": [
    "# read params\n",
    "with open(\"config/train.params\") as f:\n",
    "    learning_rate=float(params.read_param(f.readline()))\n",
    "    batch_size=int(params.read_param(f.readline()))\n",
    "    epoch=int(params.read_param(f.readline()))\n",
    "   \n",
    "    print(\"training with a learning rate of {} for {} epochs with batchs of size {}\".format(learning_rate,epoch,batch_size))\n",
    "\n",
    "    \n",
    "data_all=np.array(sorted(path.construct_path_lists(\"out\",\"data_\")))\n",
    "label_all=np.array(sorted(path.construct_path_lists(\"out\",\"labels_\")))\n",
    "# print(data_all.shape,label_all.shape)\n",
    "\n",
    "print(\"initiating network...\")\n",
    "net=network.R2N2(learning_rate)\n",
    "print(\" ...network initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=np.load(\"/Users/micmelesse/Documents/thesis/aws/model_0.1_5_10 2018-01-30_17:07:54/epoch_003/loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=7\n",
    "sample_data=np.load(data_all[i])\n",
    "sample_label=np.load(label_all[i])\n",
    "utils.imsave_sequence(sample_data[:,:,:,0],\"seq_{}.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=\"out/model_{}_{}_{} {}\".format(learning_rate,epoch,batch_size,datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "# train network\n",
    "loss_all=[]\n",
    "acc_all=[]\n",
    "N=len(data_all)\n",
    "print(\"starting training\")\n",
    "for e in range(epoch):\n",
    "    start_time=time.time()\n",
    "    perm=np.random.permutation(N)\n",
    "    data_all=data_all[perm]\n",
    "    label_all=label_all[perm]\n",
    "    split_size=math.ceil(N/batch_size)\n",
    "    data_batchs=np.array_split(data_all,split_size)\n",
    "    label_batchs=np.array_split(label_all,split_size)\n",
    "    \n",
    "    loss_epoch=[]\n",
    "    acc_epoch=[]\n",
    "    batch_number=0\n",
    "    for data,label in zip(data_batchs,label_batchs):\n",
    "        data=utils.npy_stack(data)\n",
    "        label=utils.npy_stack(label)\n",
    "        fd={net.X:data, net.Y: label}\n",
    "        train_step=net.train_step(fd)\n",
    "        loss_epoch.append(net.batch_loss.eval(fd))\n",
    "        print(\"epoch_{:03d}-batch_{:03d}: loss={}\".format(e,batch_number,loss_epoch[-1]))\n",
    "        batch_number+=1\n",
    "    save_dir=\"{}/epoch_{:03d}\".format(model_dir,e)\n",
    "    loss_all.append(loss_epoch)\n",
    "    net.save(save_dir,\"loss\",loss_all)\n",
    "    print(\"epoch %d took %d seconds\"%(e,time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
