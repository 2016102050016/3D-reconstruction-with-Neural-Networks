{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.params as params\n",
    "import lib.network as network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read params\n",
    "\n",
    "with open(\"config/train.params\") as f:\n",
    "    learning_rate=float(params.read_param(f.readline()))\n",
    "    batch_size=int(params.read_param(f.readline()))\n",
    "    epoch=int(params.read_param(f.readline()))\n",
    "   \n",
    "    print(\"training with a learning rate of {} for {} epochs with batchs of size {}\".format(learning_rate,epoch,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=np.load(\"out/all_data.npy\")  \n",
    "label_all=np.load(\"out/all_labels.npy\")\n",
    "print(data_all.shape,label_all.shape)\n",
    "\n",
    "#prep for training\n",
    "net=network.R2N2(learning_rate)\n",
    "model_dir=\"out/model_{}_{}_{}\".format(learning_rate,batch_size,epoch)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "loss_all=[]\n",
    "acc_all=[]\n",
    "N=len(data_all)\n",
    "for e in range(epoch):\n",
    "    start_time=time.time()\n",
    "    perm=np.random.permutation(N)\n",
    "    data_all=data_all[perm]\n",
    "    label_all=label_all[perm]\n",
    "    split_size=math.ceil(N/batch_size)\n",
    "    data_batchs=np.array_split(data_all,split_size)\n",
    "    label_batchs=np.array_split(label_all,split_size)\n",
    "    loss_epoch=[]\n",
    "    acc_epoch=[]\n",
    "    \n",
    "    batch_number=0\n",
    "    for data,label in zip(data_batchs,label_batchs):\n",
    "        fd={net.X:data, net.Y: label}\n",
    "        batch_info=net.sess.run([net.mean_loss,net.mean_accuracy,net.optimizing_op],feed_dict=fd)\n",
    "        loss_batch,acc_batch=batch_info[0],batch_info[1]\n",
    "        loss_epoch.append(loss_batch)\n",
    "        acc_epoch.append(acc_batch)\n",
    "        batch_number+=1\n",
    "        print(\"epoch_{:03d}-batch_{:03d}: loss={}, acc={}\".format(e,batch_number,loss_batch,acc_batch))\n",
    "            \n",
    "    loss_all.append(loss_epoch)\n",
    "    acc_all.append(acc_epoch)\n",
    "    net.save(\"{}/epoch_{:03d}\".format(model_dir,e),loss_all,acc_all)\n",
    "    print(\"epoch %d took %d seconds\"%(e,time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
