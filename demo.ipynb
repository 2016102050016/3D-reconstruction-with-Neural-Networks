{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import utils\n",
    "import random\n",
    "import layers\n",
    "import dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from network import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with a learning rate of 0.1 for 3 epochs with batchs of size 10\n"
     ]
    }
   ],
   "source": [
    "#read params\n",
    "regex=\"^.*=(.*)$\"\n",
    "with open(\"train.params\") as f:\n",
    "    learning_rate=float(re.findall(regex,f.readline())[0])\n",
    "    batch_size=int(re.findall(regex,f.readline())[0])\n",
    "    epoch=int(re.findall(regex,f.readline())[0])\n",
    "   \n",
    "    print(\"training with a learning rate of {} for {} epochs with batchs of size {}\".format(learning_rate,epoch,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep for training\n",
    "net=network(learning_rate)\n",
    "model_dir=\"model_{}_{}_{}\".format(learning_rate,batch_size,epoch)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "data_all=np.load(\"all_data.npy\")  \n",
    "label_all=np.load(\"all_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "loss_all=[]\n",
    "acc_all=[]\n",
    "for e in range(epoch):\n",
    "    start_time=time.time()\n",
    "    perm=np.random.permutation(len(data_all))\n",
    "    data_all=data_all[perm]\n",
    "    label_all=label_all[perm]\n",
    "    split_size=math.ceil(N/batch_size)\n",
    "    data_batchs=np.array_split(data_all,split_size)\n",
    "    label_batchs=np.array_split(label_all,split_size)\n",
    "    loss_epoch=[]\n",
    "    acc_epoch=[]\n",
    "\n",
    "    batch_number=0\n",
    "    for data,label in zip(data_batchs,label_batchs):\n",
    "        batch_info=sess.run([net.mean_loss,net.mean_accuracy,net.optimizing_op],feed_dict={net.X:data, net.Y: label})\n",
    "        loss_batch=batch_info[0]\n",
    "        acc_batch=batch_info[1]\n",
    "        loss_epoch.append(loss_batch)\n",
    "        acc_epoch.append(acc_batch)\n",
    "        batch_number+=1\n",
    "        if batch_number%10==0:\n",
    "            print(\"epoch_{:03d}-batch_{:03d}: loss={}, acc={}\".format(e,batch_number,loss_batch,acc_batch))\n",
    "    loss_all.append(loss_epoch)\n",
    "    acc_all.append(acc_epoch)\n",
    "    net.save(\"{}/epoch_{:03d}\".format(train_dir,e),loss_all,acc_all)\n",
    "    print(\"epoch took %d seconds\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
